{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d30540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "\n",
    "while year < 2025:\n",
    "    # construct url\n",
    "    url = \"https://en.wikipedia.org/wiki/1906_Tour_de_France\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape wikipedia page\n",
    "def scrape(url):\n",
    "    # need header to scrape from wikipedia\n",
    "    headers = {\n",
    "        'User-Agent': 'SchoolProjectBot/1.0 (r1043412@student.thomasmore.be) Python-Requests/2.31.0'\n",
    "    }\n",
    "    page = requests.get(url, headers=headers)\n",
    "    \n",
    "    return BS(page.text, \"html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4088b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take information from BeautifulSoup and clean it\n",
    "def extract_clean_data(soup):\n",
    "    # extract the table from the page html\n",
    "    table = soup.find('table', class_ = 'wikitable')\n",
    "\n",
    "    # use list comprehension instead of for loop\n",
    "    courses = [\n",
    "        # take all td's and put them in a list 'cells', take the second and third elements from that list\n",
    "        (lambda cells: (cells[1].get_text(strip=True), cells[2].get_text(strip=True)))(row.find_all(\"td\"))\n",
    "        # take all rows exept title and results row\n",
    "        for row in table.select('tr')[1:-1]\n",
    "    ]\n",
    "\n",
    "    # clean data so we can later perform analisys on it\n",
    "    courses = [\n",
    "        (lambda course:\n",
    "        (course[0][:re.search('to[A-Z]', course[0]).start()], # start of course\n",
    "        course[0][re.search('to[A-Z]', course[0]).end()-1:], # end of course\n",
    "        course[1][:re.search(r'\\D', course[1]).start()]) # distance of course\n",
    "        )(course)\n",
    "        for course in courses\n",
    "    ]\n",
    "\n",
    "    # transfer list of cleaned data to a dictionary so it can be written to json\n",
    "    data_dict = [\n",
    "        {'key': i, 'start': course[0], 'end': course[1], 'distance': course[2]}\n",
    "        # use enumerate for the counter\n",
    "        for i, course in enumerate(courses, start=1)\n",
    "    ]\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e271b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to json\n",
    "def write_json(dict, year, course_type):\n",
    "    # open the json file and update it with the python dictionary\n",
    "    with open(f'data/{course_type}.json', 'r+') as file:\n",
    "        # load the entire json file into memory\n",
    "        file_json = json.load(file)\n",
    "\n",
    "        # update the json with the python dictionary\n",
    "        file_json[course_type].update({year: dict})\n",
    "\n",
    "        # put cursor at beginning of file and overwrite it with the dictionary in memory\n",
    "        file.seek(0)\n",
    "        json.dump(file_json, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
