{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b28d302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf8b256",
   "metadata": {},
   "source": [
    "# Q1: What's the average length of a stage, and how does differ between different tours over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "995d9da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1906', [{'key': 1, 'start': 'Paris', 'end': 'Lille', 'distance': '275'}, {'key': 2, 'start': 'Douai', 'end': 'Nancy', 'distance': '400'}, {'key': 3, 'start': 'Nancy', 'end': 'Dijon', 'distance': '416'}, {'key': 4, 'start': 'Dijon', 'end': 'Grenoble', 'distance': '311'}, {'key': 5, 'start': 'Grenoble', 'end': 'Nice', 'distance': '345'}, {'key': 6, 'start': 'Nice', 'end': 'Marseille', 'distance': '292'}, {'key': 7, 'start': 'Marseille', 'end': 'Toulouse', 'distance': '480'}, {'key': 8, 'start': 'Toulouse', 'end': 'Bayonne', 'distance': '300'}, {'key': 9, 'start': 'Bayonne', 'end': 'Bordeaux', 'distance': '338'}, {'key': 10, 'start': 'Bordeaux', 'end': 'Nantes', 'distance': '391'}, {'key': 11, 'start': 'Nantes', 'end': 'Brest', 'distance': '321'}, {'key': 12, 'start': 'Brest', 'end': 'Caen', 'distance': '415'}, {'key': 13, 'start': 'Caen', 'end': 'Paris', 'distance': '259'}])\n",
      "('1909', [{'key': 1, 'start': 'Milan', 'end': 'Bologna', 'distance': '397'}, {'key': 2, 'start': 'Bologna', 'end': 'Chieti', 'distance': '375'}, {'key': 3, 'start': 'Chieti', 'end': 'Naples', 'distance': '242'}, {'key': 4, 'start': 'Naples', 'end': 'Rome', 'distance': '228'}, {'key': 5, 'start': 'Rome', 'end': 'Florence', 'distance': '346'}, {'key': 6, 'start': 'Florence', 'end': 'Genoa', 'distance': '294'}, {'key': 7, 'start': 'Genoa', 'end': 'Turin', 'distance': '354'}, {'key': 8, 'start': 'Turin', 'end': 'Milan', 'distance': '206'}])\n",
      "('1935', [{'key': 1, 'start': 'Madrid', 'end': 'Valladolid', 'distance': '185'}, {'key': 2, 'start': 'Valladolid ', 'end': 'Santander', 'distance': '251'}, {'key': 3, 'start': 'Santander ', 'end': 'Bilbao', 'distance': '199'}, {'key': 4, 'start': 'Bilbao ', 'end': 'San Sebasti치n', 'distance': '235'}, {'key': 5, 'start': 'San Sebasti치n ', 'end': 'Zaragoza', 'distance': '264'}, {'key': 6, 'start': 'Zaragoza ', 'end': 'Barcelona', 'distance': '310'}, {'key': 7, 'start': 'Barcelona ', 'end': 'Tortosa', 'distance': '188'}, {'key': 8, 'start': 'Tortosa ', 'end': 'Valencia', 'distance': '188'}, {'key': 9, 'start': 'Valencia ', 'end': 'Murcia', 'distance': '265'}, {'key': 10, 'start': 'Murcia ', 'end': 'Granada', 'distance': '285'}, {'key': 11, 'start': 'Granada ', 'end': 'Sevilla', 'distance': '260'}, {'key': 12, 'start': 'Sevilla ', 'end': 'C치ceres', 'distance': '270'}, {'key': 13, 'start': 'C치ceres ', 'end': 'Zamora', 'distance': '275'}])\n"
     ]
    }
   ],
   "source": [
    "def get_grand_tour_distances(grand_tour):\n",
    "    with open(f'data/{grand_tour}.json', 'r') as file:\n",
    "        tour_json = json.load(file)\n",
    "\n",
    "    print(list(tour_json[grand_tour].items())[0])\n",
    "\n",
    "    distances_per_year = [\n",
    "        {'year': year[0], 'distances': [course['distance'] for course in year[1]]}\n",
    "        for year in list(tour_json[grand_tour].items())\n",
    "    ]\n",
    "\n",
    "    return distances_per_year\n",
    "\n",
    "# maybe do with map\n",
    "france_dict = get_grand_tour_distances('tour_de_france')\n",
    "italia_dict = get_grand_tour_distances('giro_ditalia')\n",
    "espagna_dict = get_grand_tour_distances('vuelta_a_espagna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7f0c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year': '1906', 'distances': ['275', '400', '416', '311', '345', '292', '480', '300', '338', '391', '321', '415', '259']}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the resolved dtypes are not compatible with add.reduce. Resolved (dtype('<U3'), dtype('<U3'), dtype('<U6'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tour_dict[\u001b[32m0\u001b[39m])\n\u001b[32m      3\u001b[39m     [\n\u001b[32m      4\u001b[39m         tour_dict[i].update({\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m: np.mean(year[\u001b[33m'\u001b[39m\u001b[33mdistances\u001b[39m\u001b[33m'\u001b[39m]), \u001b[33m'\u001b[39m\u001b[33maverage\u001b[39m\u001b[33m'\u001b[39m: np.average(year[\u001b[33m'\u001b[39m\u001b[33mdistances\u001b[39m\u001b[33m'\u001b[39m])})\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tour_dict, start=\u001b[32m0\u001b[39m)\n\u001b[32m      6\u001b[39m     ]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mget_mean_average_per_year\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfrance_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m get_mean_average_per_year(italia_dict)\n\u001b[32m     10\u001b[39m get_mean_average_per_year(espagna_dict)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_mean_average_per_year\u001b[39m\u001b[34m(tour_dict)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_mean_average_per_year\u001b[39m(tour_dict):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tour_dict[\u001b[32m0\u001b[39m])\n\u001b[32m      3\u001b[39m     [\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         tour_dict[i].update({\u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdistances\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m'\u001b[39m\u001b[33maverage\u001b[39m\u001b[33m'\u001b[39m: np.average(year[\u001b[33m'\u001b[39m\u001b[33mdistances\u001b[39m\u001b[33m'\u001b[39m])})\n\u001b[32m      5\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i, year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tour_dict, start=\u001b[32m0\u001b[39m)\n\u001b[32m      6\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/DataScience/Project/Project-Data-Science-UR-TM-2025/project-venv/lib64/python3.13/site-packages/numpy/_core/fromnumeric.py:3860\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3857\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3858\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis=axis, dtype=dtype, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3860\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3861\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/School/DataScience/Project/Project-Data-Science-UR-TM-2025/project-venv/lib64/python3.13/site-packages/numpy/_core/_methods.py:134\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    131\u001b[39m         dtype = mu.dtype(\u001b[33m'\u001b[39m\u001b[33mf4\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    132\u001b[39m         is_float16_result = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m ret = \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu.ndarray):\n\u001b[32m    136\u001b[39m     ret = um.true_divide(\n\u001b[32m    137\u001b[39m             ret, rcount, out=ret, casting=\u001b[33m'\u001b[39m\u001b[33munsafe\u001b[39m\u001b[33m'\u001b[39m, subok=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: the resolved dtypes are not compatible with add.reduce. Resolved (dtype('<U3'), dtype('<U3'), dtype('<U6'))"
     ]
    }
   ],
   "source": [
    "def get_mean_average_per_year(tour_dict):\n",
    "    print(tour_dict[0])\n",
    "    [\n",
    "        tour_dict[i].update({'mean': np.mean(year['distances']), 'average': np.average(year['distances'])})\n",
    "        for i, year in enumerate(tour_dict, start=0)\n",
    "    ]\n",
    "\n",
    "get_mean_average_per_year(france_dict)\n",
    "get_mean_average_per_year(italia_dict)\n",
    "get_mean_average_per_year(espagna_dict)\n",
    "\n",
    "# maybe expand with the average of all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f982b",
   "metadata": {},
   "source": [
    "# Q2: What rider has finished a tour the most with each jersey in the Tour de France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e650aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jerseys.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Yellow Jersey\n",
    "yellow_data = data['yellow'][0]\n",
    "max_yellow = max(map(lambda x: int(x['jerseys']), yellow_data))\n",
    "top_yellow = [r['name'] for r in yellow_data if int(r['jerseys']) == max_yellow]\n",
    "\n",
    "# White Jersey\n",
    "white_data = data['white'][0]\n",
    "max_white = max(white_data.values())\n",
    "top_white = [name for name, count in white_data.items() if count == max_white]\n",
    "\n",
    "# Polka Dot Jersey\n",
    "dotted_data = data['dotted'][0]\n",
    "max_dotted = max(dotted_data.values())\n",
    "top_dotted = [name for name, count in dotted_data.items() if count == max_dotted]\n",
    "\n",
    "# Green Jersey\n",
    "green_data = data['green'][0]\n",
    "max_green = max(green_data.values())\n",
    "top_green = [name for name, count in green_data.items() if count == max_green]\n",
    "\n",
    "# Results\n",
    "results = {\n",
    "    'Yellow': (max_yellow, top_yellow),\n",
    "    'White': (max_white, top_white),\n",
    "    'Polka Dot': (max_dotted, top_dotted),\n",
    "    'Green': (max_green, top_green)\n",
    "}\n",
    "\n",
    "for jersey, (count, riders) in results.items():\n",
    "    print(f\"\\n{jersey} Jersey - {count} wins:\")\n",
    "    print(f\"  {', '.join(riders)}\")\n",
    "\n",
    "# Summary\n",
    "maxes = np.array([max_yellow, max_white, max_dotted, max_green])\n",
    "print(f\"\\nHighest record: {np.max(maxes)} wins | Average: {np.mean(maxes):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387a92a0",
   "metadata": {},
   "source": [
    "# Q3 Which riders switch teams most often and which are most loyal of the current riders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open('rider_teams.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "rider_groups = data['rider'][1:]  # Skip \"dummy\"\n",
    "\n",
    "rider_stats = []\n",
    "for group in rider_groups:\n",
    "    for rider in group:\n",
    "        teams = rider['teams']\n",
    "        rider_stats.append({\n",
    "            'name': rider['name'],\n",
    "            'unique_teams': len(set(teams)),\n",
    "            'total_entries': len(teams),\n",
    "            'teams': teams\n",
    "        })\n",
    "\n",
    "# Most switches (most unique teams)\n",
    "most_switches = sorted(rider_stats, key=lambda x: x['unique_teams'], reverse=True)[:10]\n",
    "\n",
    "# Most loyal (fewest unique teams, min 5 entries)\n",
    "experienced = [r for r in rider_stats if r['total_entries'] >= 5]\n",
    "most_loyal = sorted(experienced, key=lambda x: x['unique_teams'])[:10]\n",
    "\n",
    "print(\"\\nTOP 10 TEAM SWITCHERS:\")\n",
    "for i, r in enumerate(most_switches, 1):\n",
    "    ratio = r['total_entries']/r['unique_teams']\n",
    "    print(f\"{i}. {r['name']}: {r['unique_teams']} teams ({r['total_entries']} entries, {ratio:.1f}x/team)\")\n",
    "\n",
    "print(\"\\nTOP 10 MOST LOYAL (min 5 entries):\")\n",
    "for i, r in enumerate(most_loyal, 1):\n",
    "    ratio = r['total_entries']/r['unique_teams']\n",
    "    main_team = Counter(r['teams']).most_common(1)[0]\n",
    "    print(f\"{i}. {r['name']}: {r['unique_teams']} teams ({r['total_entries']} entries, {ratio:.1f}x/team)\")\n",
    "    print(f\"   Main: {main_team[0]} ({main_team[1]}x)\")\n",
    "\n",
    "# Summary\n",
    "avg_unique = sum(r['unique_teams'] for r in rider_stats) / len(rider_stats)\n",
    "avg_entries = sum(r['total_entries'] for r in rider_stats) / len(rider_stats)\n",
    "print(f\"\\nAvg: {avg_unique:.1f} teams, {avg_entries:.1f} entries, {avg_entries/avg_unique:.1f}x/team\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa4994",
   "metadata": {},
   "source": [
    "# Q4 How has the age of the average tour winner evolved over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc407a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('ages.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "victors = data['victors'][0]\n",
    "\n",
    "# Extract year and calculate age\n",
    "ages_by_decade = defaultdict(list)\n",
    "all_ages = []\n",
    "\n",
    "for victor in victors:\n",
    "    year = int(victor['year'])\n",
    "    \n",
    "    # Try to get birthyear - some entries might not have it\n",
    "    if 'birthyear' in victor and victor['birthyear']:\n",
    "        birthyear = int(victor['birthyear'])\n",
    "        age = year - birthyear\n",
    "        \n",
    "        decade = (year // 10) * 10\n",
    "        ages_by_decade[decade].append(age)\n",
    "        all_ages.append((year, age, victor['rider']))\n",
    "\n",
    "# Calculate statistics by decade\n",
    "print(\"AVERAGE AGE OF TOUR WINNERS BY DECADE:\\n\")\n",
    "for decade in sorted(ages_by_decade.keys()):\n",
    "    ages = ages_by_decade[decade]\n",
    "    avg = np.mean(ages)\n",
    "    min_age = min(ages)\n",
    "    max_age = max(ages)\n",
    "    print(f\"{decade}s: {avg:.1f} years (range: {min_age}-{max_age})\")\n",
    "\n",
    "# Recent trends (last 30 years)\n",
    "recent_30 = [age for year, age, _ in all_ages if year >= 1995]\n",
    "older_30 = [age for year, age, _ in all_ages if year < 1995 and year >= 1965]\n",
    "\n",
    "print(f\"\\nTREND COMPARISON:\")\n",
    "print(f\"1965-1994: {np.mean(older_30):.1f} years average\")\n",
    "print(f\"1995-2025: {np.mean(recent_30):.1f} years average\")\n",
    "print(f\"Change: {np.mean(recent_30) - np.mean(older_30):+.1f} years\")\n",
    "\n",
    "# Youngest and oldest winners\n",
    "sorted_ages = sorted(all_ages, key=lambda x: x[1])\n",
    "print(f\"\\nYOUNGEST WINNERS:\")\n",
    "for year, age, rider in sorted_ages[:5]:\n",
    "    print(f\"{rider.replace('1', '')}: {age} years ({year})\")\n",
    "\n",
    "print(f\"\\nOLDEST WINNERS:\")\n",
    "for year, age, rider in sorted_ages[-5:]:\n",
    "    print(f\"{rider.replace('1', '')}: {age} years ({year})\")\n",
    "\n",
    "# Overall statistics\n",
    "ages_only = [age for _, age, _ in all_ages]\n",
    "print(f\"\\nOVERALL STATISTICS:\")\n",
    "print(f\"Mean age: {np.mean(ages_only):.1f} years\")\n",
    "print(f\"Median age: {np.median(ages_only):.1f} years\")\n",
    "print(f\"Std deviation: {np.std(ages_only):.1f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f270ca",
   "metadata": {},
   "source": [
    "# Q5 How has the nationality of the podiums evolved over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "with open('ages.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "country_data = data['country'][1]  # Skip null at index 0\n",
    "\n",
    "# Map country codes to full names\n",
    "country_names = {\n",
    "    'fr': 'France', 'be': 'Belgium', 'it': 'Italy', 'es': 'Spain', 'nl': 'Netherlands',\n",
    "    'gb': 'Great Britain', 'us': 'USA', 'lu': 'Luxembourg', 'ch': 'Switzerland',\n",
    "    'de': 'Germany', 'ie': 'Ireland', 'au': 'Australia', 'dk': 'Denmark',\n",
    "    'co': 'Colombia', 'si': 'Slovenia', 'ec': 'Ecuador', 'at': 'Austria',\n",
    "    'pt': 'Portugal', 'kz': 'Kazakhstan', 'lt': 'Lithuania', 'lv': 'Latvia',\n",
    "    'pl': 'Poland', 'ru': 'Russia', 'se': 'Sweden'\n",
    "}\n",
    "\n",
    "# Analyze by decade\n",
    "decades = defaultdict(lambda: {'countries': [], 'years': []})\n",
    "\n",
    "for entry in country_data:\n",
    "    year = int(entry['year'])\n",
    "    decade = (year // 10) * 10\n",
    "    \n",
    "    for country_code in entry['countries']:\n",
    "        country = country_names.get(country_code, country_code.upper())\n",
    "        decades[decade]['countries'].append(country)\n",
    "        decades[decade]['years'].append(year)\n",
    "\n",
    "# Display results by decade\n",
    "print(\"PODIUM NATIONALITIES BY DECADE:\\n\")\n",
    "for decade in sorted(decades.keys()):\n",
    "    counts = Counter(decades[decade]['countries'])\n",
    "    total_podiums = len(decades[decade]['countries'])\n",
    "    \n",
    "    print(f\"{decade}s ({len(set(decades[decade]['years']))} Tours):\")\n",
    "    for country, count in counts.most_common(5):\n",
    "        pct = (count / total_podiums) * 100\n",
    "        print(f\"  {country}: {count} ({pct:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "# Era comparisons\n",
    "eras = {\n",
    "    'Early (1903-1939)': [y for y in range(1903, 1940)],\n",
    "    'Post-War (1947-1970)': [y for y in range(1947, 1971)],\n",
    "    'Modern (1971-2000)': [y for y in range(1971, 2001)],\n",
    "    'Recent (2001-2025)': [y for y in range(2001, 2026)]\n",
    "}\n",
    "\n",
    "print(\"DOMINANT NATIONS BY ERA:\\n\")\n",
    "for era_name, years in eras.items():\n",
    "    era_countries = []\n",
    "    for entry in country_data:\n",
    "        if int(entry['year']) in years:\n",
    "            era_countries.extend([country_names.get(c, c.upper()) for c in entry['countries']])\n",
    "    \n",
    "    if era_countries:\n",
    "        counts = Counter(era_countries)\n",
    "        total = len(era_countries)\n",
    "        print(f\"{era_name}:\")\n",
    "        for country, count in counts.most_common(3):\n",
    "            print(f\"  {country}: {count}/{total} ({count/total*100:.1f}%)\")\n",
    "        print()\n",
    "\n",
    "# Diversity analysis\n",
    "print(\"NATIONALITY DIVERSITY:\\n\")\n",
    "recent_decades = [1990, 2000, 2010, 2020]\n",
    "for decade in recent_decades:\n",
    "    decade_countries = []\n",
    "    for entry in country_data:\n",
    "        year = int(entry['year'])\n",
    "        if decade <= year < decade + 10:\n",
    "            decade_countries.extend([country_names.get(c, c.upper()) for c in entry['countries']])\n",
    "    \n",
    "    unique = len(set(decade_countries))\n",
    "    print(f\"{decade}s: {unique} different countries represented\")\n",
    "\n",
    "# Recent dominance (last 10 years)\n",
    "recent = [entry for entry in country_data if int(entry['year']) >= 2015]\n",
    "recent_countries = []\n",
    "for entry in recent:\n",
    "    recent_countries.extend([country_names.get(c, c.upper()) for c in entry['countries']])\n",
    "\n",
    "print(f\"\\nLAST 10 YEARS (2015-2025):\")\n",
    "for country, count in Counter(recent_countries).most_common():\n",
    "    print(f\"{country}: {count} podiums\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
